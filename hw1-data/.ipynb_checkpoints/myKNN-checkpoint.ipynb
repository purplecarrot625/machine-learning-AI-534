{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f72762a-59d4-49e2-b144-da52ab6acb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedf8b5e-6c7c-48fe-a976-74b849e4a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "names = [\"age\", \"sector\", \"education\", \"marital-status\", \"occupation\", \"race\", \"sex\", \"hours-per-week\", \"country-of-origin\", \"target\"]\n",
    "data = pd.read_csv(\"income.train.txt.5k\", names = names)\n",
    "dev_data = pd.read_csv(\"income.dev.txt\", names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e04170-d8ca-4fd9-b8a3-ee6a975cae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_processor = MinMaxScaler(feature_range=(0, 2))\n",
    "cat_processor = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "           ('num', num_processor, ['age', 'hours-per-week']),\n",
    "           ('sector', cat_processor, ['sector']),\n",
    "           ('education', cat_processor, ['education']),\n",
    "           ('marital-status', cat_processor, ['marital-status']),\n",
    "           ('occupation', cat_processor, ['occupation']),\n",
    "           ('race', cat_processor, ['race']),\n",
    "           ('sex', cat_processor, ['sex']),\n",
    "           ('country', cat_processor, ['country-of-origin']),\n",
    "       ])\n",
    "preprocessor.fit(data)\n",
    "processed_data = preprocessor.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f640ba8-bd94-47ee-b696-253dd73d9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = processed_data\n",
    "y_train = (data[\"target\"].str.strip() == '>50K').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50b4050-4ca6-4268-8a65-b70540f0a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_data = preprocessor.transform(dev_data)\n",
    "X_dev = processed_dev_data\n",
    "y_dev = (dev_data[\"target\"].str.strip() == '>50K').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21635ed0-b155-4ebb-9422-1570162b30b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90410959, 0.24489796, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.57534247, 0.79591837, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.98630137, 0.79591837, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.20547945, 0.08163265, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.68493151, 0.79591837, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.10958904, 0.79591837, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6af2d8-3c89-440a-90c7-648dee047b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "331d78ad-3810-4489-825e-627b376ee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(X, p):\n",
    "    #diff = X - p\n",
    "    #return np.sqrt(np.sum(diff ** 2, axis = 1))\n",
    "    return np.linalg.norm(X - p, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ed8358-b3ad-4a0d-bf91-2dc39a20d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(X, p):\n",
    "    #return np.sum(np.abs(X - p), axis = 1)\n",
    "     return np.linalg.norm(X - p, ord=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5ba65f-1d51-4ce1-a578-87cf840f23e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      3\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m      5\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mkneighbors(X_dev[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "distances, indices = knn.kneighbors(X_dev[0])\n",
    "# Print results\n",
    "print(\"Top 3 closest individuals' indices:\", indices [0])\n",
    "print(\"Their Euclidean distances:\", distances [0])\n",
    "closest_people = X_train[indices[0]]\n",
    "print(closest_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb95fd-06ee-48c1-9fbf-696a010c8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean' )\n",
    "knn.fit(X_train, y_train)\n",
    "euclidean_distances, _= knn.kneighbors (IX_dev[011)\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "knn_manhattan. fit (X_train, y_train)\n",
    "manhattan_distances, _ = knn_manhattan.kneighbors(X_dev[0])\n",
    "print (\"Sklearn Euclidean distances:\",euclidean_distances [0])\n",
    "print (\"Sklearn Manhattan distances:\",manhattan_distances [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b4848a4-d818-4443-9be9-5f2c7854b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_knn(X_train, y_train, x, k, distance_func):\n",
    "    distances = distance_func(X_train, x) # compute the distances between X_train and the data point ehich we want to predict the label\n",
    "    k_indices = np.argsort(distances)[:k] # Get the top k nearest neighbors\n",
    "    k_nearest_labels = y_train[k_indices] # Get their corresponding labels from y_train.\n",
    "    most_common = Counter(k_nearest_labels).most_common(1) # Majority voting\n",
    "    return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd451f28-5c47-470a-a308-78c3fec32730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=41: Training Error Rate = 0.1728, Dev Error Rate = 0.1410\n",
      "k=41: Training Error Rate = 0.1728, Dev Error Rate = 0.1410, Train Positive Rate = 0.2110, Dev Positive Rate = 0.2070\n",
      "k=43: Training Error Rate = 0.1752, Dev Error Rate = 0.1440\n",
      "k=43: Training Error Rate = 0.1752, Dev Error Rate = 0.1440, Train Positive Rate = 0.2074, Dev Positive Rate = 0.2020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 6\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmy_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanhattan_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     train_preds\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[1;32m      8\u001b[0m dev_preds \u001b[38;5;241m=\u001b[39m [my_knn(X_train, y_train, X_dev[i], k, manhattan_distance) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_dev\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mmy_knn\u001b[0;34m(X_train, y_train, x, k, distance_func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_knn\u001b[39m(X_train, y_train, x, k, distance_func):\n\u001b[0;32m----> 2\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# compute the distances between X_train and the data point ehich we want to predict the label\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     k_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:k] \u001b[38;5;66;03m# Get the top k nearest neighbors\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     k_nearest_labels \u001b[38;5;241m=\u001b[39m y_train[k_indices] \u001b[38;5;66;03m# Get their corresponding labels from y_train.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m, in \u001b[0;36mmanhattan_distance\u001b[0;34m(X, p)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmanhattan_distance\u001b[39m(X, p):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#return np.sum(np.abs(X - p), axis = 1)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2379\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(svd(y, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 2379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm_dispatcher\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x,)\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnorm\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for k in range(1, 101, 2):\n",
    "    train_preds = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        pred = my_knn(X_train, y_train, X_train[i], k, manhattan_distance)\n",
    "        train_preds.append(pred)\n",
    "    dev_preds = [my_knn(X_train, y_train, X_dev[i], k, manhattan_distance) for i in range(X_dev.shape[0])]\n",
    "    \n",
    "    train_error_rate = 1 - accuracy_score(y_train, train_preds)\n",
    "    dev_error_rate = 1 - accuracy_score(y_dev, dev_preds)\n",
    "    \n",
    "    print(f\"k={k}: Training Error Rate = {train_error_rate:.4f}, Dev Error Rate = {dev_error_rate:.4f}\")\n",
    "\n",
    "# Calculate positive rates\n",
    "    # train_positive_rate = sum(train_preds) / len(train_preds)\n",
    "    # dev_positive_rate = sum(dev_preds) / len(dev_preds)\n",
    "    \n",
    "    # print(f\"k={k}: Training Error Rate = {train_error_rate:.4f}, Dev Error Rate = {dev_error_rate:.4f}, Train Positive Rate = {train_positive_rate:.4f}, Dev Positive Rate = {dev_positive_rate:.4f}\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8997e-e560-4117-bf84-71acec078136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2bcfbf3-8efc-4306-8f09-7907d64ac8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the `income.test.blind` dataset\n",
    "# Note: Since the 'target' column doesn't exist in the blind dataset, we'll exclude it from the names list when reading the data.\n",
    "blind_names = names[:-1]\n",
    "blind_data = pd.read_csv(\"income.test.blind\", names=blind_names)\n",
    "\n",
    "# 2. Preprocess the `income.test.blind` dataset\n",
    "processed_blind_data = preprocessor.transform(blind_data)\n",
    "X_blind = processed_blind_data\n",
    "\n",
    "# 3. Predict the outcomes using my kNN model.\n",
    "best_k = 41\n",
    "blind_preds = [my_knn(X_train, y_train, X_blind[i], best_k, euclidean_distance) for i in range(X_blind.shape[0])]\n",
    "\n",
    "# Convert integer predictions back to string format\n",
    "blind_predictions = [\">50K\" if pred == 1 else \"<=50K\" for pred in blind_preds]\n",
    "\n",
    "# 4. Write the predictions to the `income.test.predicted` file\n",
    "with open(\"income.test.predicted\", \"w\") as f:\n",
    "    for idx, pred in enumerate(blind_predictions):\n",
    "        # Combine the original data with the prediction\n",
    "        original_data = \", \".join(map(str, blind_data.iloc[idx].values))\n",
    "        f.write(original_data + \", \" + pred + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0436f5f8-e9ec-4479-bdab-45354e1e944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall True Positive %: 0.6229\n",
      "Overall Predicted Positive %: 0.2020\n"
     ]
    }
   ],
   "source": [
    "# Positve analysis\n",
    "# Overall\n",
    "true_positives = sum((y_dev == 1) & (np.array(dev_preds) == 1))\n",
    "actual_positives = sum(y_dev == 1)\n",
    "predicted_positives = sum(dev_preds)\n",
    "\n",
    "true_positive_percentage = true_positives / actual_positives\n",
    "predicted_positive_percentage = predicted_positives / len(dev_preds)\n",
    "\n",
    "print(f\"Overall True Positive %: {true_positive_percentage:.4f}\")\n",
    "print(f\"Overall Predicted Positive %: {predicted_positive_percentage:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97dc4de7-9680-447a-bbf9-e5ba27324796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Female - True Positive %: 0.4500\n",
      "For Female - Predicted Positive %: 0.0667\n"
     ]
    }
   ],
   "source": [
    "# Given Gender\n",
    "gender = 'Female'\n",
    "female_indices = dev_data['sex'].str.strip() == gender\n",
    "\n",
    "female_true_labels = y_dev[female_indices]\n",
    "female_predictions = np.array(dev_preds)[female_indices]\n",
    "\n",
    "true_positives_female = sum((female_true_labels == 1) & (female_predictions == 1))\n",
    "actual_positives_female = sum(female_true_labels == 1)\n",
    "predicted_positives_female = sum(female_predictions)\n",
    "\n",
    "true_positive_percentage_female = true_positives_female / actual_positives_female\n",
    "predicted_positive_percentage_female = predicted_positives_female / len(female_predictions)\n",
    "\n",
    "print(f\"For {gender} - True Positive %: {true_positive_percentage_female:.4f}\")\n",
    "print(f\"For {gender} - Predicted Positive %: {predicted_positive_percentage_female:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc52da90-5630-4f85-9f00-88a28cec2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For White - True Positive %: 0.6324\n",
      "For White - Predicted Positive %: 0.2180\n"
     ]
    }
   ],
   "source": [
    "race = 'White'  # for example\n",
    "race_indices = dev_data['race'].str.strip() == race\n",
    "\n",
    "race_true_labels = y_dev[race_indices]\n",
    "race_predictions = np.array(dev_preds)[race_indices]\n",
    "\n",
    "true_positives_race = sum((race_true_labels == 1) & (race_predictions == 1))\n",
    "actual_positives_race = sum(race_true_labels == 1)\n",
    "predicted_positives_race = sum(race_predictions)\n",
    "\n",
    "true_positive_percentage_race = true_positives_race / actual_positives_race\n",
    "predicted_positive_percentage_race = predicted_positives_race / len(race_predictions)\n",
    "\n",
    "print(f\"For {race} - True Positive %: {true_positive_percentage_race:.4f}\")\n",
    "print(f\"For {race} - Predicted Positive %: {predicted_positive_percentage_race:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4022860-a4f1-4215-b7e6-07fc87bba9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
