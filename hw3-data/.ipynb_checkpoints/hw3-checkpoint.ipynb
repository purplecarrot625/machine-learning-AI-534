{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd244be-df24-4e8a-9309-33027263a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts for each field:\n",
      "Id: 1314\n",
      "MSSubClass: 15\n",
      "MSZoning: 5\n",
      "LotFrontage: 107\n",
      "LotArea: 989\n",
      "Street: 2\n",
      "Alley: 2\n",
      "LotShape: 4\n",
      "LandContour: 4\n",
      "Utilities: 2\n",
      "LotConfig: 5\n",
      "LandSlope: 3\n",
      "Neighborhood: 25\n",
      "Condition1: 9\n",
      "Condition2: 8\n",
      "BldgType: 5\n",
      "HouseStyle: 8\n",
      "OverallQual: 10\n",
      "OverallCond: 9\n",
      "YearBuilt: 110\n",
      "YearRemodAdd: 61\n",
      "RoofStyle: 6\n",
      "RoofMatl: 8\n",
      "Exterior1st: 15\n",
      "Exterior2nd: 16\n",
      "MasVnrType: 3\n",
      "MasVnrArea: 304\n",
      "ExterQual: 4\n",
      "ExterCond: 5\n",
      "Foundation: 6\n",
      "BsmtQual: 4\n",
      "BsmtCond: 4\n",
      "BsmtExposure: 4\n",
      "BsmtFinType1: 6\n",
      "BsmtFinSF1: 601\n",
      "BsmtFinType2: 6\n",
      "BsmtFinSF2: 131\n",
      "BsmtUnfSF: 730\n",
      "TotalBsmtSF: 686\n",
      "Heating: 6\n",
      "HeatingQC: 4\n",
      "CentralAir: 2\n",
      "Electrical: 5\n",
      "1stFlrSF: 721\n",
      "2ndFlrSF: 390\n",
      "LowQualFinSF: 21\n",
      "GrLivArea: 810\n",
      "BsmtFullBath: 4\n",
      "BsmtHalfBath: 3\n",
      "FullBath: 4\n",
      "HalfBath: 3\n",
      "BedroomAbvGr: 8\n",
      "KitchenAbvGr: 4\n",
      "KitchenQual: 4\n",
      "TotRmsAbvGrd: 12\n",
      "Functional: 7\n",
      "Fireplaces: 4\n",
      "FireplaceQu: 5\n",
      "GarageType: 6\n",
      "GarageYrBlt: 96\n",
      "GarageFinish: 3\n",
      "GarageCars: 5\n",
      "GarageArea: 422\n",
      "GarageQual: 5\n",
      "GarageCond: 5\n",
      "PavedDrive: 3\n",
      "WoodDeckSF: 253\n",
      "OpenPorchSF: 193\n",
      "EnclosedPorch: 116\n",
      "3SsnPorch: 17\n",
      "ScreenPorch: 72\n",
      "PoolArea: 8\n",
      "PoolQC: 3\n",
      "Fence: 4\n",
      "MiscFeature: 4\n",
      "MiscVal: 21\n",
      "MoSold: 12\n",
      "YrSold: 5\n",
      "SaleType: 9\n",
      "SaleCondition: 6\n",
      "SalePrice: 624\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Get the number of unique values of each category \"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv('my_train.csv')\n",
    "\n",
    "unique_counts = {}\n",
    "for column in df.columns:\n",
    "    unique_counts[column] = df[column].nunique()\n",
    "print(\"Unique value counts for each field:\")\n",
    "for field, count in unique_counts.items():\n",
    "    print(f\"{field}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0e66b6e-2832-42af-9ae5-c61b90812bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Positive Features:\n",
      "                   Feature    Coefficient\n",
      "277        PoolQC_missing  265865.782104\n",
      "128      RoofMatl_Membran  137717.033597\n",
      "133      RoofMatl_WdShngl  114277.343147\n",
      "129        RoofMatl_Metal  102092.066192\n",
      "102       Condition2_PosA   98741.957380\n",
      "259         GarageQual_Ex   87534.061440\n",
      "125        RoofStyle_Shed   67446.969683\n",
      "99      Condition2_Artery   52054.724610\n",
      "131      RoofMatl_Tar&Grv   45775.149628\n",
      "87   Neighborhood_StoneBr   44101.310195\n",
      "\n",
      "Top 10 Most Negative Features:\n",
      "               Feature    Coefficient\n",
      "64      LandSlope_Sev  -27170.191823\n",
      "262     GarageQual_Po  -33800.980324\n",
      "240    Functional_Sev  -33826.682802\n",
      "228    Electrical_Mix  -34426.156709\n",
      "104   Condition2_RRAe  -75258.088116\n",
      "265     GarageCond_Ex  -82418.172324\n",
      "276         PoolQC_Gd -126232.159564\n",
      "275         PoolQC_Fa -153639.689603\n",
      "103   Condition2_PosN -191625.940796\n",
      "126  RoofMatl_ClyTile -520189.208076\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols.remove('SalePrice')  # Exclude the target variable from the features\n",
    "\n",
    "# numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "    ('scaler', StandardScaler())  # Standardize numerical features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Processor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_data.drop('SalePrice', axis=1))\n",
    "X_dev = preprocessor.transform(dev_data.drop('SalePrice', axis=1))\n",
    "\n",
    "# target\n",
    "y_train = train_data['SalePrice']\n",
    "y_dev = dev_data['SalePrice']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "coefficients = model.coef_\n",
    "onehot_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = np.concatenate([numerical_cols, onehot_feature_names])\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the features by their coefficients\n",
    "sorted_features = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Extract the top 10 most positive and negative features\n",
    "top_10_positive = sorted_features.head(10)\n",
    "top_10_negative = sorted_features.tail(10)\n",
    "\n",
    "print(\"Top 10 Most Positive Features is:\\n\", top_10_positive)\n",
    "print(\"\\nTop 10 Most Negative Features is:\\n\", top_10_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e1532a3-898f-4a6a-b2ae-340411ad6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error (RMSLE): 0.15233137894779697\n"
     ]
    }
   ],
   "source": [
    "\"\"\" naive approach \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "# Convert all fields to strings\n",
    "train_data = train_data.astype(str)\n",
    "dev_data = dev_data.astype(str)\n",
    "\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = dev_data['SalePrice'].astype(float) \n",
    "\n",
    "# Dropping the 'Id' column and the target variable from the datasets\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "cat_processor = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "categorical_features = list(X_train.columns)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline that first transforms the data and then applies linear regression\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', LinearRegression())])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "y_dev_pred = np.exp(y_dev_pred_log)\n",
    "\n",
    "# Compute the Root Mean Squared Log Error (RMSLE)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_dev, y_dev_pred))\n",
    "\n",
    "print(f\"Root Mean Squared Log Error (RMSLE): {rmsle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92737842-cfa0-4418-ab12-700c16711d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most positive features:\n",
      "FullBath_3: 0.1384868955128779\n",
      "OverallQual_9: 0.13777419218234832\n",
      "Neighborhood_StoneBr: 0.12192484382630553\n",
      "2ndFlrSF_472: 0.1117291881713578\n",
      "OverallQual_8: 0.10845606473475708\n",
      "RoofMatl_WdShngl: 0.09399030509045228\n",
      "GrLivArea_1192: 0.08998259228027972\n",
      "Neighborhood_NoRidge: 0.08973706153848256\n",
      "LotArea_8029: 0.08741275605842641\n",
      "GarageCars_3: 0.08656765942192202\n",
      "\n",
      "Top 10 most negative features:\n",
      "MSZoning_C (all): -0.2008037480372122\n",
      "GrLivArea_968: -0.1275052412263517\n",
      "EnclosedPorch_236: -0.12296424688865087\n",
      "OverallQual_3: -0.11659502734479932\n",
      "LotArea_8281: -0.10903583425995617\n",
      "BsmtFinSF2_311: -0.10793872586682125\n",
      "OverallCond_3: -0.10047231859640178\n",
      "GarageCars_1: -0.0947984976593521\n",
      "OverallQual_1: -0.08972090034376787\n",
      "YearRemodAdd_1958: -0.08911884159630307\n"
     ]
    }
   ],
   "source": [
    "coefficients = model_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "feature_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(input_features=categorical_features)\n",
    "\n",
    "feature_importance = dict(zip(feature_names, coefficients))\n",
    "\n",
    "sorted_features = sorted(feature_importance.items(), key=lambda x: x[1])\n",
    "\n",
    "# Top 10 most positive features\n",
    "top_10_positive = sorted_features[-10:]\n",
    "\n",
    "# Top 10 most negative features\n",
    "top_10_negative = sorted_features[:10]\n",
    "\n",
    "print(\"Top 10 most positive features:\")\n",
    "for feature, coeff in reversed(top_10_positive):\n",
    "    print(f\"{feature}: {coeff}\")\n",
    "\n",
    "print(\"\\nTop 10 most negative features:\")\n",
    "for feature, coeff in top_10_negative:\n",
    "    print(f\"{feature}: {coeff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b66bf89-4419-4cad-8069-04e154c4d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'test.csv' \n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data = test_data.astype(str)\n",
    "\n",
    "# Dropping the 'Id' column from the test dataset\n",
    "X_test = test_data.drop(['Id'], axis=1)  \n",
    "\n",
    "y_test_pred_log = model_pipeline.predict(X_test)\n",
    "\n",
    "# Convert predictions back to SalePrice scale\n",
    "y_test_pred = np.exp(y_test_pred_log)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'].astype(int),\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "\n",
    "submission_file_path = 'my_submission_new.csv'\n",
    "submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5899ba5-e41e-4475-b601-42c62e11e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error (RMSLE): 0.12409284941384163\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Smarter binarization \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = dev_data['SalePrice'].astype(float)\n",
    "\n",
    "# Dropping the 'Id' column and the target variable from the datasets\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "# Columns with only numerical data and no missing values\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "\n",
    "# Columns with numerical data and NaN values\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "\n",
    "# (categorical data)\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "# Pipeline for numerical features without missing values\n",
    "num_processor_no_na = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline for numerical features with missing values\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "\n",
    "y_dev_pred = np.exp(y_dev_pred_log)\n",
    "\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_dev, y_dev_pred))\n",
    "\n",
    "print(f\"Root Mean Squared Log Error (RMSLE): {rmsle}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bb36e8a-75b3-4b09-924d-0594471eb257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features after preprocessing: 302\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "print(f\"Total number of features after preprocessing: {X_train_transformed.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc5a4bb0-72df-4a38-bd10-88d508151e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most positive features:\n",
      "PoolQC_missing: 0.6484730654621055\n",
      "RoofMatl_Membran: 0.6156025139091502\n",
      "RoofMatl_Metal: 0.4778672079085623\n",
      "Condition2_PosA: 0.441465476230923\n",
      "RoofStyle_Shed: 0.3280193561429262\n",
      "RoofMatl_Roll: 0.2876307282108068\n",
      "GarageQual_Ex: 0.2864310168436186\n",
      "RoofMatl_WdShngl: 0.2820118951349435\n",
      "RoofMatl_Tar&Grv: 0.244268997579583\n",
      "RoofMatl_CompShg: 0.22494321463375203\n",
      "\n",
      "Top 10 most negative features:\n",
      "PoolQC_Ex: -0.1865461330682581\n",
      "Exterior1st_BrkComm: -0.18924145797255412\n",
      "Functional_Maj2: -0.20583117343247515\n",
      "Functional_Sev: -0.20882843799231643\n",
      "GarageCond_Ex: -0.2553870578691189\n",
      "PoolQC_Fa: -0.3162664812072812\n",
      "MSZoning_C (all): -0.3337389127677652\n",
      "Condition2_RRAe: -0.47314646828927226\n",
      "Condition2_PosN: -0.7333125045673314\n",
      "RoofMatl_ClyTile: -2.3178679573931675\n"
     ]
    }
   ],
   "source": [
    "model_pipeline.fit(X_train, y_train)\n",
    "coefficients = model_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Extracting feature names for one-hot encoded categorical features\n",
    "cat_feature_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat']['onehot'].get_feature_names_out(categorical)\n",
    "feature_names = np.concatenate([cat_feature_names, \n",
    "                                numerical_no_na, \n",
    "                                numerical_with_na])\n",
    "feature_importance = sorted(zip(coefficients, feature_names), reverse=True)\n",
    "\n",
    "# Top 10 most positive features\n",
    "top_10_positive = feature_importance[:10]\n",
    "print(\"Top 10 most positive features:\")\n",
    "for coef, name in top_10_positive:\n",
    "    print(f\"{name}: {coef}\")\n",
    "\n",
    "# Top 10 most negative features\n",
    "top_10_negative = feature_importance[-10:]\n",
    "print(\"\\nTop 10 most negative features:\")\n",
    "for coef, name in top_10_negative:\n",
    "    print(f\"{name}: {coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cf0c50e-3cd0-4d04-ae58-b22f8119cda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_submission_my_train.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Generate smart binarization submission file to Kaggle\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "my_train_data_path = 'my_train.csv'  \n",
    "test_data_path = 'test.csv'         \n",
    "train_data = pd.read_csv(my_train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "\n",
    "# Dropping the 'Id' column and the target variable from the training dataset\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "# Identifying columns\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "num_processor_no_na = Pipeline([('scaler', StandardScaler())])\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "X_test = test_data.drop(['Id'], axis=1)\n",
    "\n",
    "# Handling missing values and potentially problematic data in the test dataset\n",
    "for col in X_train.columns:\n",
    "    if col in numerical_with_na:\n",
    "        mean_value = train_data[col].mean()\n",
    "        X_test[col].fillna(mean_value, inplace=True)\n",
    "    elif col in categorical and col not in X_test.columns:\n",
    "        X_test[col] = 'missing'\n",
    "\n",
    "# Check for and handle any infinite values\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Re-checking for any remaining NaN values after all imputations and replacements\n",
    "if X_test.isna().any().any():\n",
    "    for col in X_test.columns:\n",
    "        # Corrected way to check if a column is numerical\n",
    "        if np.issubdtype(X_test[col].dtype, np.number):\n",
    "            mean_value = train_data[col].mean()\n",
    "            X_test[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "X_test = X_test[X_train.columns]\n",
    "y_test_pred_log = model_pipeline.predict(X_test)\n",
    "\n",
    "y_test_pred = np.exp(y_test_pred_log)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'].astype(int),\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "submission_file_path = 'my_submission_my_train.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "submission_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "068678d7-5bd1-492a-bc3e-41020f39f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, RMSLE: 0.12425552294130057\n",
      "Alpha: 0.1, RMSLE: 0.12501976868293904\n",
      "Alpha: 1, RMSLE: 0.12808332371263367\n",
      "Alpha: 10, RMSLE: 0.1275838451122021\n",
      "Alpha: 100, RMSLE: 0.12810048975884905\n",
      "Best Alpha: 0.01, Best RMSLE: 0.12425552294130057\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 4.1 - sb \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = dev_data['SalePrice'].astype(float) \n",
    "\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "\n",
    "# Columns with numerical data and NaN values\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "\n",
    "# Columns with strings (categorical data)\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "# Pipeline for numerical features without missing values\n",
    "num_processor_no_na = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline for numerical features with missing values\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# Define a range of alpha values for tuning\n",
    "alpha_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_alpha = None\n",
    "best_rmsle = float('inf')\n",
    "\n",
    "# Loop through each alpha value\n",
    "for alpha in alpha_values:\n",
    "    # Update the model in the pipeline\n",
    "    model_pipeline.set_params(regressor=Ridge(alpha=alpha))\n",
    "    \n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "    y_dev_pred = np.exp(y_dev_pred_log)\n",
    "    \n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(f\"Alpha: {alpha}, RMSLE: {rmsle}\")\n",
    "    if rmsle < best_rmsle:\n",
    "        best_rmsle = rmsle\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best RMSLE: {best_rmsle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20bb52fc-3625-4a19-8c54-42e0c037dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, RMSLE: 0.15011200318735915\n",
      "Alpha: 0.1, RMSLE: 0.14472911780389117\n",
      "Alpha: 1, RMSLE: 0.14060827537615866\n",
      "Alpha: 10, RMSLE: 0.13946014128405673\n",
      "Alpha: 100, RMSLE: 0.15430911822131044\n",
      "Best Alpha: 10, Best RMSLE: 0.13946014128405673\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 4.1 naive \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "# Convert all fields to strings\n",
    "train_data = train_data.astype(str)\n",
    "dev_data = dev_data.astype(str)\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = dev_data['SalePrice'].astype(float)\n",
    "\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "cat_processor = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "categorical_features = list(X_train.columns)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline that first transforms the data and then applies Ridge regression\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', Ridge())])\n",
    "\n",
    "# Define a range of alpha values for tuning\n",
    "alpha_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_alpha = None\n",
    "best_rmsle = float('inf')\n",
    "\n",
    "# Loop through each alpha value\n",
    "for alpha in alpha_values:\n",
    "    # Update the model in the pipeline\n",
    "    model_pipeline.set_params(regressor=Ridge(alpha=alpha))\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the dev set\n",
    "    y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "    y_dev_pred = np.exp(y_dev_pred_log)\n",
    "    \n",
    "    # Compute the RMSLE\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(f\"Alpha: {alpha}, RMSLE: {rmsle}\")\n",
    "\n",
    "    # Update the best alpha if the current one is better\n",
    "    if rmsle < best_rmsle:\n",
    "        best_rmsle = rmsle\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best RMSLE: {best_rmsle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "134b44e8-dcc9-468e-8c5b-c218a4cca874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error (RMSLE): 0.14956303869696996\n"
     ]
    }
   ],
   "source": [
    "\"\"\" PolynomialFeatures \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Load the datasets\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = np.log(dev_data['SalePrice'].astype(float))\n",
    "\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Creating a pipeline with PolynomialFeatures and LinearRegression\n",
    "polynomial_regression = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "polynomial_regression.fit(X_train, y_train)\n",
    "y_dev_pred_log = polynomial_regression.predict(X_dev)\n",
    "\n",
    "rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(y_dev_pred_log)))\n",
    "\n",
    "print(f\"Root Mean Squared Log Error (RMSLE): {rmsle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1bf30bd-cc83-47b5-bfc6-472d4d9f2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to my_submission_non_linear.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "my_train_data_path = 'my_train.csv'  \n",
    "test_data_path = 'test.csv'       \n",
    "train_data = pd.read_csv(my_train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "# Identifying columns\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "# Creating pipelines for data preprocessing\n",
    "num_processor_no_na = Pipeline([('scaler', StandardScaler())])\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Creating the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline with PolynomialFeatures\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "X_test = test_data.drop(['Id'], axis=1)\n",
    "\n",
    "# Handling missing values and potentially problematic data in the test dataset\n",
    "for col in X_train.columns:\n",
    "    if col in numerical_with_na:\n",
    "        mean_value = train_data[col].mean()\n",
    "        X_test[col].fillna(mean_value, inplace=True)\n",
    "    elif col in categorical and col not in X_test.columns:\n",
    "        X_test[col] = 'missing'\n",
    "\n",
    "# Check for and handle any infinite values\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Re-checking for any remaining NaN values after all imputations and replacements\n",
    "if X_test.isna().any().any():\n",
    "    for col in X_test.columns:\n",
    "        if np.issubdtype(X_test[col].dtype, np.number):\n",
    "            mean_value = train_data[col].mean()\n",
    "            X_test[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "# Predict on the test set (in logarithmic scale)\n",
    "y_test_pred_log = model_pipeline.predict(X_test)\n",
    "\n",
    "# Convert predictions back to SalePrice scale\n",
    "y_test_pred = np.exp(y_test_pred_log)\n",
    "\n",
    "# Create a DataFrame for the submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'].astype(int),\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "\n",
    "submission_file_path = 'my_submission_non_linear.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "48ece8f1-e8ce-432d-831d-45d829e6e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.13009862823472093\n"
     ]
    }
   ],
   "source": [
    "\"\"\" more:GradientBoostingRegressor \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "gbr_params = {\n",
    "    'n_estimators': 300,  # 50, 100, 200\n",
    "    'learning_rate': 0.01,  # 0.01, 0.05, 0.1, 0.2\n",
    "    'max_depth': 50, \n",
    "    'min_samples_split': 3,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'log2',  # Can be a fraction (e.g., 0.3) or 'sqrt', 'log2'\n",
    "    'subsample': 0.9  # Values slightly less than 1 can help with overfitting\n",
    "}\n",
    "\n",
    "# Creating a pipeline with the GradientBoostingRegressor and parameters\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(**gbr_params))\n",
    "])\n",
    "\n",
    "# Rest of your code for fitting and evaluating the model...\n",
    "\n",
    "# Load the datasets\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "\n",
    "# Extracting the target variable 'SalePrice', converting to float, and taking the logarithm\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = dev_data['SalePrice'].astype(float)  # Keeping original SalePrice for evaluation\n",
    "\n",
    "# Dropping the 'Id' column and the target variable from the datasets\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "# Columns with only numerical data and no missing values\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "\n",
    "# Columns with numerical data and NaN values\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "\n",
    "# Columns with strings (categorical data)\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "# Pipeline for numerical features without missing values\n",
    "num_processor_no_na = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline for numerical features with missing values\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Creating the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline with GradientBoostingRegressor\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the dev set\n",
    "y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "y_dev_pred = np.exp(y_dev_pred_log)\n",
    "\n",
    "# Compute the RMSLE\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_dev, y_dev_pred))\n",
    "\n",
    "print(f\"RMSLE: {rmsle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "705b8e35-083c-4408-8a0e-ca244101572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on dev set: 0.1305113109020391\n",
      "Submission file saved as p2_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train_data_path = 'my_train.csv'\n",
    "dev_data_path = 'my_dev.csv'\n",
    "test_data_path = 'test.csv'  # Replace with the correct path to your test dataset\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "dev_data = pd.read_csv(dev_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Extracting the target variable 'SalePrice', converting to float, and taking the logarithm\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = np.log(dev_data['SalePrice'].astype(float))  # Use log for consistent error metric\n",
    "\n",
    "# Dropping the 'Id' column and the target variable from the datasets\n",
    "X_train = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "X_dev = dev_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "# Identify columns\n",
    "numerical_no_na = X_train.select_dtypes(include=[np.number]).dropna(axis=1).columns.tolist()\n",
    "numerical_with_na = X_train.select_dtypes(include=[np.number]).columns[X_train.select_dtypes(include=[np.number]).isna().any()].tolist()\n",
    "categorical = X_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "num_processor_no_na = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "num_processor_with_na = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Creating the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_processor, categorical),\n",
    "        ('num_no_na', num_processor_no_na, numerical_no_na),\n",
    "        ('num_with_na', num_processor_with_na, numerical_with_na)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline with GradientBoostingRegressor\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_dev_pred_log = model_pipeline.predict(X_dev)\n",
    "y_dev_pred = np.exp(y_dev_pred_log)\n",
    "\n",
    "# Compute the RMSLE\n",
    "rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), y_dev_pred))\n",
    "print(f\"RMSLE on dev set: {rmsle}\")\n",
    "\n",
    "# Handling missing values and potentially problematic data in the test dataset\n",
    "X_test = test_data.drop(['Id'], axis=1)\n",
    "for col in X_train.columns:\n",
    "    if col in numerical_with_na:\n",
    "        mean_value = train_data[col].mean()\n",
    "        X_test[col].fillna(mean_value, inplace=True)\n",
    "    elif col in categorical and col not in X_test.columns:\n",
    "        X_test[col] = 'missing'\n",
    "\n",
    "# Check for and handle any infinite values\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Re-checking for any remaining NaN values after all imputations and replacements\n",
    "if X_test.isna().any().any():\n",
    "    for col in X_test.columns:\n",
    "        if np.issubdtype(X_test[col].dtype, np.number):\n",
    "            mean_value = train_data[col].mean()\n",
    "            X_test[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "y_test_pred_log = model_pipeline.predict(X_test)\n",
    "y_test_pred = np.exp(y_test_pred_log)\n",
    "\n",
    "test_ids = test_data['Id']\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_file_path = 'p2_submission.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved as {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493e728-10ce-43af-a4b9-f0bc5f30919f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
