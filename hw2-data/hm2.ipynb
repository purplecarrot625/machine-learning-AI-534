{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "04494225-5613-4595-a5c9-dc29abe44ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division # no need for python3, but just in case used w/ python2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from svector import svector\n",
    "\n",
    "def read_from(textfile):\n",
    "    for line in open(textfile):\n",
    "        label, words = line.strip().split(\"\\t\")\n",
    "        yield (1 if label==\"+\" else -1, words.split())\n",
    "\n",
    "def make_vector(words, bias=True):\n",
    "    v = svector()\n",
    "    for word in words:\n",
    "        v[word] += 1\n",
    "    if bias:\n",
    "        v['<bias>'] = 1\n",
    "    return v\n",
    "    \n",
    "def test(devfile, model):\n",
    "    tot, err = 0, 0\n",
    "    for i, (label, words) in enumerate(read_from(devfile), 1): # note 1...|D|\n",
    "        err += label * (model.dot(make_vector(words, bias=True))) <= 0\n",
    "    return err/i  # i is |D| now\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e67d3be-25f8-4ddc-948d-e7cb14629a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(trainfile, devfile, epochs=5):\n",
    "    t = time.time()\n",
    "    best_err = 1.0\n",
    "    model = svector()\n",
    "    cumulative_model = svector()\n",
    "    updates = 0\n",
    "\n",
    "    for it in range(1, epochs + 1):\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1):\n",
    "            sent = make_vector(words, bias=True)\n",
    "            activation = model.dot(sent)\n",
    "            if label * activation <= 0:\n",
    "                update = label * sent\n",
    "                model += update\n",
    "                updates += 1\n",
    "            cumulative_model += model\n",
    "        \n",
    "        # Calculate the averaged model at the end of each epoch\n",
    "        if updates > 0:\n",
    "            averaged_model = cumulative_model * (1/updates)\n",
    "        else:\n",
    "            averaged_model = model.copy()\n",
    "\n",
    "        # Test the averaged model on the development set\n",
    "        dev_err = test(devfile, averaged_model)\n",
    "        best_err = min(best_err, dev_err)\n",
    "        print(f\"epoch {it}, updates {updates / i:.1f}%, dev {dev_err * 100:.1f}%\")\n",
    "\n",
    "    # Final averaged model is calculated outside the loop after all epochs\n",
    "    if updates > 0:\n",
    "        averaged_model = cumulative_model * (1/updates)\n",
    "    else:\n",
    "        averaged_model = model.copy()\n",
    "\n",
    "    print(f\"best dev err {best_err * 100:.1f}%, |w|={len(model)}, time: {time.time() - t:.1f} secs\")\n",
    "    return averaged_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78a3d855-c6dc-4584-8367-def1995f0e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, updates 0.4%, dev 31.4%\n",
      "epoch 2, updates 0.6%, dev 27.7%\n",
      "epoch 3, updates 0.9%, dev 27.2%\n",
      "epoch 4, updates 1.0%, dev 27.6%\n",
      "epoch 5, updates 1.2%, dev 27.2%\n",
      "epoch 6, updates 1.3%, dev 26.7%\n",
      "epoch 7, updates 1.4%, dev 26.3%\n",
      "epoch 8, updates 1.5%, dev 26.4%\n",
      "epoch 9, updates 1.6%, dev 26.3%\n",
      "epoch 10, updates 1.6%, dev 26.3%\n",
      "best dev err 26.3%, |w|=15806, time: 79.4 secs\n"
     ]
    }
   ],
   "source": [
    "trainfile = 'train.txt'\n",
    "devfile = 'dev.txt'\n",
    "model = train(trainfile, devfile, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2946336d-da50-485f-b2ce-03c2508bd9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive features:\n",
      "engrossing\n",
      "triumph\n",
      "unexpected\n",
      "rare\n",
      "provides\n",
      "french\n",
      "skin\n",
      "treat\n",
      "pulls\n",
      "culture\n",
      "cinema\n",
      "dots\n",
      "wonderful\n",
      "refreshingly\n",
      "open\n",
      "powerful\n",
      "delightful\n",
      "imax\n",
      "smarter\n",
      "flaws\n",
      "\n",
      "Top negative features:\n",
      "boring\n",
      "generic\n",
      "dull\n",
      "badly\n",
      "routine\n",
      "fails\n",
      "ill\n",
      "too\n",
      "instead\n",
      "tv\n",
      "attempts\n",
      "unless\n",
      "incoherent\n",
      "neither\n",
      "flat\n",
      "seagal\n",
      "problem\n",
      "scattered\n",
      "worst\n",
      "suffers\n"
     ]
    }
   ],
   "source": [
    "# Get the top 20 most positive and negative features\n",
    "def print_top_features(model, top_n=20):\n",
    "    # Sort the features by weight\n",
    "    sorted_features = sorted(model.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Top positive features\n",
    "    top_positive_features = sorted_features[:top_n]\n",
    "    # Top negative features\n",
    "    top_negative_features = sorted_features[-top_n:]\n",
    "    \n",
    "    print(\"Top positive features:\")\n",
    "    for feature, weight in top_positive_features:\n",
    "        print(f\"{feature}\")\n",
    "    \n",
    "    print(\"\\nTop negative features:\")\n",
    "    for feature, weight in top_negative_features[::-1]:\n",
    "        print(f\"{feature}\")\n",
    "print_top_features(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a34fa199-0ca0-437f-8917-ab81cb1a6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative examples that are strongly predicted as positive:\n",
      "Review: ` in this poor remake of such a well loved classic , parker exposes the limitations of his skill and the basic flaws in his vision '\n",
      "\n",
      "\n",
      "Review: how much you are moved by the emotional tumult of fran ois and mich le 's relationship depends a lot on how interesting and likable you find them\n",
      "\n",
      "\n",
      "Review: bravo reveals the true intent of her film by carefully selecting interview subjects who will construct a portrait of castro so predominantly charitable it can only be seen as propaganda\n",
      "\n",
      "\n",
      "Review: mr wollter and ms seldhal give strong and convincing performances , but neither reaches into the deepest recesses of the character to unearth the quaking essence of passion , grief and fear\n",
      "\n",
      "\n",
      "Review: an atonal estrogen opera that demonizes feminism while gifting the most sympathetic male of the piece with a nice vomit bath at his wedding\n",
      "\n",
      "\n",
      "\n",
      "Positive examples that are strongly predicted as negative:\n",
      "Review: the thing about guys like evans is this you 're never quite sure where self promotion ends and the truth begins but as you watch the movie , you 're too interested to care\n",
      "\n",
      "\n",
      "Review: neither the funniest film that eddie murphy nor robert de niro has ever made , showtime is nevertheless efficiently amusing for a good while before it collapses into exactly the kind of buddy cop comedy it set out to lampoon , anyway\n",
      "\n",
      "\n",
      "Review: even before it builds up to its insanely staged ballroom scene , in which 3000 actors appear in full regalia , it 's waltzed itself into the art film pantheon\n",
      "\n",
      "\n",
      "Review: if i have to choose between gorgeous animation and a lame story ( like , say , treasure planet ) or so so animation and an exciting , clever story with a batch of appealing characters , i 'll take the latter every time\n",
      "\n",
      "\n",
      "Review: carrying off a spot on scottish burr , duvall ( also a producer ) peels layers from this character that may well not have existed on paper\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_misclassified(devfile, model):\n",
    "    misclassified_as_positive = []\n",
    "    misclassified_as_negative = []\n",
    "\n",
    "    for label, words in read_from(devfile):\n",
    "        features = make_vector(words, bias=True)\n",
    "        score = model.dot(features)\n",
    "        prediction = 1 if score > 0 else -1\n",
    "\n",
    "        # For negative -> positive\n",
    "        if label == -1 and prediction == 1:\n",
    "            misclassified_as_positive.append((score, words))\n",
    "\n",
    "        # For positive -> negative\n",
    "        elif label == 1 and prediction == -1:\n",
    "            misclassified_as_negative.append((score, words))\n",
    "\n",
    "    # Sort by confidence (absolute score)\n",
    "    misclassified_as_positive.sort(key=lambda x: abs(x[0]), reverse=True)\n",
    "    misclassified_as_negative.sort(key=lambda x: abs(x[0]), reverse=True)\n",
    "\n",
    "    return misclassified_as_positive[:5], misclassified_as_negative[:5]\n",
    "\n",
    "misclassified_positive, misclassified_negative = find_misclassified(devfile, model)\n",
    "\n",
    "print(\"Negative examples that are strongly predicted as positive:\")\n",
    "for score, words in misclassified_positive:\n",
    "    print(f\"Review: {' '.join(words)}\")\n",
    "    print(f\"\\n\")\n",
    "\n",
    "print(\"\\nPositive examples that are strongly predicted as negative:\")\n",
    "for score, words in misclassified_negative:\n",
    "    print(f\"Review: {' '.join(words)}\")\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5dd5780-4386-4238-801e-3bcce1338a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Filter out the one-count words\n",
    "def build_vocabulary(trainfile):\n",
    "    word_counts = Counter()\n",
    "    for _, words in read_from(trainfile):\n",
    "        word_counts.update(words)\n",
    "    return set(word for word, count in word_counts.items() if count > 1)\n",
    "\n",
    "def make_vector(words, vocabulary, bias=True):\n",
    "    v = svector()\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            v[word] += 1\n",
    "    if bias:\n",
    "        v['<bias>'] = 1\n",
    "    return v\n",
    "    \n",
    "def test(devfile, model, vocabulary):\n",
    "    tot, err = 0, 0\n",
    "    for i, (label, words) in enumerate(read_from(devfile), 1): # note 1...|D|\n",
    "        # Only use words that are in the vocabulary\n",
    "        err += label * (model.dot(make_vector(words, vocabulary, bias=True))) <= 0\n",
    "    return err/i  # i is |D| now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f512ead-72ff-4298-980d-306c19a3809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_neglecting_one_count_word(trainfile, devfile, epochs=10):\n",
    "    vocabulary = build_vocabulary(trainfile)  # Assume this excludes one-count words\n",
    "    t = time.time()\n",
    "    best_err = 1.0\n",
    "    model = svector()\n",
    "    cumulative_model = svector()\n",
    "    updates = 0\n",
    "\n",
    "    for it in range(1, epochs + 1):\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1):\n",
    "            # Filter out one-count words based on the vocabulary built\n",
    "            filtered_words = [word for word in words if word in vocabulary]\n",
    "            sent = make_vector(filtered_words, vocabulary, bias=True)\n",
    "            activation = model.dot(sent)\n",
    "            if label * activation <= 0:\n",
    "                updates += 1\n",
    "                update = label * sent\n",
    "                model += update\n",
    "\n",
    "            # Correctly add the current model to the cumulative model\n",
    "            cumulative_model += model\n",
    "        \n",
    "        # Correctly calculate the averaged model at the end of each epoch\n",
    "        if updates > 0:\n",
    "            averaged_model = cumulative_model * (1 / updates)\n",
    "        else:\n",
    "            averaged_model = model.copy()\n",
    "\n",
    "        # Test the averaged model on the development set\n",
    "        dev_err = test(devfile, averaged_model, vocabulary)\n",
    "        best_err = min(best_err, dev_err)\n",
    "        print(f\"epoch {it}, updates {updates / i:.1f}%, dev {dev_err * 100:.1f}%\")\n",
    "\n",
    "    if updates > 0:\n",
    "        averaged_model = cumulative_model * (1 / updates)\n",
    "    else:\n",
    "        averaged_model = model.copy()\n",
    "\n",
    "    print(f\"best dev err {best_err * 100:.1f}%, |w|={len(averaged_model)}, time: {time.time() - t:.1f} secs\")\n",
    "    return averaged_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4ab7f0c9-7f95-4495-abdb-8c3e8713abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, updates 0.4%, dev 31.6%\n",
      "epoch 2, updates 0.7%, dev 27.5%\n",
      "epoch 3, updates 0.9%, dev 26.8%\n",
      "epoch 4, updates 1.1%, dev 26.6%\n",
      "epoch 5, updates 1.2%, dev 25.9%\n",
      "epoch 6, updates 1.4%, dev 26.5%\n",
      "epoch 7, updates 1.5%, dev 27.0%\n",
      "epoch 8, updates 1.6%, dev 26.7%\n",
      "epoch 9, updates 1.8%, dev 26.6%\n",
      "epoch 10, updates 1.9%, dev 26.2%\n",
      "best dev err 25.9%, |w|=8425, time: 40.7 secs\n"
     ]
    }
   ],
   "source": [
    "trainfile = 'train.txt'\n",
    "devfile = 'dev.txt'\n",
    "model = train_neglecting_one_count_word(trainfile, devfile, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64b1aa88-bb55-49a6-9e86-2c2e19fee4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testfile, model, vocabulary, outputfile):\n",
    "    with open(outputfile, 'w') as outfile:\n",
    "        for _, words in read_from(testfile):\n",
    "            # Only use words that are in the vocabulary\n",
    "            words_filtered = [word for word in words if word in vocabulary]\n",
    "            vector = make_vector(words_filtered, vocabulary, bias=True)\n",
    "            activation = model.dot(vector)\n",
    "            label = \"+\" if activation > 0 else \"-\"\n",
    "            line = f\"{label}\\t{' '.join(words)}\\n\"\n",
    "            outfile.write(line)\n",
    "testfile = 'test.txt'\n",
    "outputfile = 'test.txt.predicted'\n",
    "predict(testfile, model, vocabulary, outputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc6e0d-1483-44c5-8496-1e33e463355b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
