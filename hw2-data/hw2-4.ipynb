{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d053f32-fa87-4c6b-b256-b19caf333796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Error: 26.00%\n",
      "Running Time: 39.39 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "def read_from(textfile):\n",
    "    for line in open(textfile):\n",
    "        label, words = line.strip().split(\"\\t\")\n",
    "        yield (1 if label == \"+\" else -1, words.split())\n",
    "\n",
    "def build_vocabulary(trainfile):\n",
    "    word_counts = Counter()\n",
    "    for _, words in read_from(trainfile):\n",
    "        word_counts.update(words)\n",
    "    return set(word for word, count in word_counts.items() if count > 1)\n",
    "\n",
    "def get_data_and_labels(file, vocabulary):\n",
    "    data, labels = [], []\n",
    "    for label, words in read_from(file):\n",
    "        # Filter words based on the vocabulary.\n",
    "        data.append(' '.join([word for word in words if word in vocabulary]))\n",
    "        labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "trainfile = 'train.txt'\n",
    "devfile = 'dev.txt'\n",
    "\n",
    "vocabulary = build_vocabulary(trainfile)\n",
    "\n",
    "# Get the data ready for training and evaluation\n",
    "train_data, train_labels = get_data_and_labels(trainfile, vocabulary)\n",
    "dev_data, dev_labels = get_data_and_labels(devfile, vocabulary)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data)\n",
    "X_dev = vectorizer.transform(dev_data)\n",
    "\n",
    "# Convert labels to a numpy array, adjusting labels to fit sklearn's expected format\n",
    "y_train = np.array([1 if label == 1 else 0 for label in train_labels])\n",
    "y_dev = np.array([1 if label == 1 else 0 for label in dev_labels])\n",
    "\n",
    "# Initialize the neural network classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, activation='relu', solver='adam')\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Train the classifier\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the development set\n",
    "dev_predictions = mlp.predict(X_dev)\n",
    "\n",
    "# Measure elapsed time\n",
    "end_time = time()\n",
    "\n",
    "dev_accuracy = accuracy_score(y_dev, dev_predictions)\n",
    "dev_error = 1 - dev_accuracy\n",
    "print(f\"Development Set Error: {dev_error * 100:.2f}%\")\n",
    "print(f\"Running Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd6a72-d3a3-494f-8990-80a55d7389fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
